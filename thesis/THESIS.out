\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Problem Context}{section.1}% 2
\BOOKMARK [1][-]{section.2}{Learning}{}% 3
\BOOKMARK [2][-]{subsection.2.1}{Neural Networks}{section.2}% 4
\BOOKMARK [3][-]{subsubsection.2.1.1}{Motivation}{subsection.2.1}% 5
\BOOKMARK [3][-]{subsubsection.2.1.2}{Neural Network Structure}{subsection.2.1}% 6
\BOOKMARK [3][-]{subsubsection.2.1.3}{Bias-per-node Representation}{subsection.2.1}% 7
\BOOKMARK [3][-]{subsubsection.2.1.4}{Choice of Activation Function}{subsection.2.1}% 8
\BOOKMARK [3][-]{subsubsection.2.1.5}{Optimization}{subsection.2.1}% 9
\BOOKMARK [3][-]{subsubsection.2.1.6}{Back-propogation}{subsection.2.1}% 10
\BOOKMARK [3][-]{subsubsection.2.1.7}{Weight Initialization}{subsection.2.1}% 11
\BOOKMARK [3][-]{subsubsection.2.1.8}{References}{subsection.2.1}% 12
\BOOKMARK [2][-]{subsection.2.2}{Kernel Density Estimation}{section.2}% 13
\BOOKMARK [2][-]{subsection.2.3}{Variational Inference}{section.2}% 14
\BOOKMARK [3][-]{subsubsection.2.3.1}{Context}{subsection.2.3}% 15
\BOOKMARK [3][-]{subsubsection.2.3.2}{Introduction to Variational Inference}{subsection.2.3}% 16
\BOOKMARK [3][-]{subsubsection.2.3.3}{Derivation of the ELBO}{subsection.2.3}% 17
\BOOKMARK [3][-]{subsubsection.2.3.4}{Mean-Field Variational Family \(need to fix notations\)}{subsection.2.3}% 18
\BOOKMARK [3][-]{subsubsection.2.3.5}{Example: Bayesian mixture of Gaussians}{subsection.2.3}% 19
\BOOKMARK [3][-]{subsubsection.2.3.6}{Amortized Inference}{subsection.2.3}% 20
\BOOKMARK [3][-]{subsubsection.2.3.7}{Example: Variational Autoencoder}{subsection.2.3}% 21
\BOOKMARK [3][-]{subsubsection.2.3.8}{References}{subsection.2.3}% 22
\BOOKMARK [1][-]{section.3}{Our Problem}{}% 23
\BOOKMARK [2][-]{subsection.3.1}{Objective Derivation}{section.3}% 24
\BOOKMARK [3][-]{subsubsection.3.1.1}{Implicit Prior}{subsection.3.1}% 25
\BOOKMARK [3][-]{subsubsection.3.1.2}{Implicit Likelihood \(\046 Prior\)}{subsection.3.1}% 26
\BOOKMARK [2][-]{subsection.3.2}{Class Probability Estimation}{section.3}% 27
\BOOKMARK [3][-]{subsubsection.3.2.1}{Procedure \(need better heading\)}{subsection.3.2}% 28
\BOOKMARK [3][-]{subsubsection.3.2.2}{Implicit Prior}{subsection.3.2}% 29
\BOOKMARK [3][-]{subsubsection.3.2.3}{Implicit Likelihood \(\046 Prior\)}{subsection.3.2}% 30
\BOOKMARK [3][-]{subsubsection.3.2.4}{Optimal functions}{subsection.3.2}% 31
\BOOKMARK [2][-]{subsection.3.3}{Divergence Minimisation}{section.3}% 32
\BOOKMARK [3][-]{subsubsection.3.3.1}{Procedure \(Again need better heading\)}{subsection.3.3}% 33
\BOOKMARK [3][-]{subsubsection.3.3.2}{Implicit Prior}{subsection.3.3}% 34
\BOOKMARK [3][-]{subsubsection.3.3.3}{Implicit Likelihood \(\046 Prior\)}{subsection.3.3}% 35
\BOOKMARK [3][-]{subsubsection.3.3.4}{Optimal functions}{subsection.3.3}% 36
\BOOKMARK [3][-]{subsubsection.3.3.5}{Alternative Derivation of Class Probability Estimation}{subsection.3.3}% 37
\BOOKMARK [1][-]{section.4}{Experiments}{}% 38
\BOOKMARK [2][-]{subsection.4.1}{Inference - "Sprinkler" Example}{section.4}% 39
\BOOKMARK [3][-]{subsubsection.4.1.1}{Problem Context}{subsection.4.1}% 40
\BOOKMARK [3][-]{subsubsection.4.1.2}{Program Structure}{subsection.4.1}% 41
\BOOKMARK [3][-]{subsubsection.4.1.3}{Results}{subsection.4.1}% 42
\BOOKMARK [2][-]{subsection.4.2}{Theorycraftintime}{section.4}% 43
\BOOKMARK [3][-]{subsubsection.4.2.1}{Introduction to my mad theory}{subsection.4.2}% 44
\BOOKMARK [3][-]{subsubsection.4.2.2}{Recap because its confusing}{subsection.4.2}% 45
\BOOKMARK [3][-]{subsubsection.4.2.3}{First and Second Derivatives of all 6 possible algorithms}{subsection.4.2}% 46
\BOOKMARK [3][-]{subsubsection.4.2.4}{Difference between divergences}{subsection.4.2}% 47
\BOOKMARK [3][-]{subsubsection.4.2.5}{Difference between estimators}{subsection.4.2}% 48
\BOOKMARK [2][-]{subsection.4.3}{Determining optimal activation function}{section.4}% 49
\BOOKMARK [3][-]{subsubsection.4.3.1}{Experiment Outline}{subsection.4.3}% 50
\BOOKMARK [3][-]{subsubsection.4.3.2}{Results}{subsection.4.3}% 51
\BOOKMARK [2][-]{subsection.4.4}{Comparing Estimator Accuracies}{section.4}% 52
\BOOKMARK [3][-]{subsubsection.4.4.1}{Experiment Outline}{subsection.4.4}% 53
\BOOKMARK [3][-]{subsubsection.4.4.2}{Results}{subsection.4.4}% 54
\BOOKMARK [2][-]{subsection.4.5}{Comparing Accuracies of Undertrained Estimators}{section.4}% 55
\BOOKMARK [3][-]{subsubsection.4.5.1}{Experiment Outline}{subsection.4.5}% 56
\BOOKMARK [3][-]{subsubsection.4.5.2}{Results}{subsection.4.5}% 57
\BOOKMARK [2][-]{subsection.4.6}{Data Generation - \(MNIST image generation\)}{section.4}% 58
\BOOKMARK [3][-]{subsubsection.4.6.1}{Problem Context}{subsection.4.6}% 59
\BOOKMARK [3][-]{subsubsection.4.6.2}{Program Structure}{subsection.4.6}% 60
\BOOKMARK [3][-]{subsubsection.4.6.3}{Results}{subsection.4.6}% 61
\BOOKMARK [1][-]{section.5}{Related Work and Discussion}{}% 62
\BOOKMARK [1][-]{section.6}{Conclusion}{}% 63
