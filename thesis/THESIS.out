\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Problem Context}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Objective Derivation}{section.1}% 3
\BOOKMARK [3][-]{subsubsection.1.2.1}{Implicit Prior}{subsection.1.2}% 4
\BOOKMARK [3][-]{subsubsection.1.2.2}{Implicit Likelihood \(\046 Prior\)}{subsection.1.2}% 5
\BOOKMARK [2][-]{subsection.1.3}{Class Probability Estimation}{section.1}% 6
\BOOKMARK [3][-]{subsubsection.1.3.1}{Procedure \(need better heading\)}{subsection.1.3}% 7
\BOOKMARK [3][-]{subsubsection.1.3.2}{Implicit Prior}{subsection.1.3}% 8
\BOOKMARK [3][-]{subsubsection.1.3.3}{Implicit Likelihood \(\046 Prior\)}{subsection.1.3}% 9
\BOOKMARK [3][-]{subsubsection.1.3.4}{Optimal functions}{subsection.1.3}% 10
\BOOKMARK [2][-]{subsection.1.4}{Divergence Minimisation}{section.1}% 11
\BOOKMARK [3][-]{subsubsection.1.4.1}{Procedure \(Again need better heading\)}{subsection.1.4}% 12
\BOOKMARK [3][-]{subsubsection.1.4.2}{Implicit Prior}{subsection.1.4}% 13
\BOOKMARK [3][-]{subsubsection.1.4.3}{Implicit Likelihood \(\046 Prior\)}{subsection.1.4}% 14
\BOOKMARK [3][-]{subsubsection.1.4.4}{Optimal functions}{subsection.1.4}% 15
\BOOKMARK [3][-]{subsubsection.1.4.5}{Ratio Error}{subsection.1.4}% 16
\BOOKMARK [3][-]{subsubsection.1.4.6}{Alternative Derivation of Class Probability Estimation}{subsection.1.4}% 17
\BOOKMARK [1][-]{section.2}{Learning}{}% 18
\BOOKMARK [2][-]{subsection.2.1}{Variational Inference}{section.2}% 19
\BOOKMARK [3][-]{subsubsection.2.1.1}{Context}{subsection.2.1}% 20
\BOOKMARK [3][-]{subsubsection.2.1.2}{Introduction to Variational Inference}{subsection.2.1}% 21
\BOOKMARK [3][-]{subsubsection.2.1.3}{Derivation of the ELBO}{subsection.2.1}% 22
\BOOKMARK [3][-]{subsubsection.2.1.4}{Mean-Field Variational Family}{subsection.2.1}% 23
\BOOKMARK [3][-]{subsubsection.2.1.5}{Example: Bayesian mixture of Gaussians}{subsection.2.1}% 24
\BOOKMARK [3][-]{subsubsection.2.1.6}{References}{subsection.2.1}% 25
\BOOKMARK [2][-]{subsection.2.2}{Neural Networks}{section.2}% 26
\BOOKMARK [3][-]{subsubsection.2.2.1}{Motivation}{subsection.2.2}% 27
\BOOKMARK [3][-]{subsubsection.2.2.2}{Neural Network Structure}{subsection.2.2}% 28
\BOOKMARK [3][-]{subsubsection.2.2.3}{Bias-per-node Representation}{subsection.2.2}% 29
\BOOKMARK [3][-]{subsubsection.2.2.4}{Optimization}{subsection.2.2}% 30
\BOOKMARK [3][-]{subsubsection.2.2.5}{Back-propogation}{subsection.2.2}% 31
\BOOKMARK [3][-]{subsubsection.2.2.6}{Weight Initialization}{subsection.2.2}% 32
\BOOKMARK [3][-]{subsubsection.2.2.7}{References}{subsection.2.2}% 33
\BOOKMARK [1][-]{section.3}{Experiments}{}% 34
\BOOKMARK [2][-]{subsection.3.1}{"Sprinkler" Example}{section.3}% 35
\BOOKMARK [3][-]{subsubsection.3.1.1}{Problem Context}{subsection.3.1}% 36
\BOOKMARK [3][-]{subsubsection.3.1.2}{Network Structure}{subsection.3.1}% 37
\BOOKMARK [3][-]{subsubsection.3.1.3}{Results}{subsection.3.1}% 38
\BOOKMARK [2][-]{subsection.3.2}{Lotka-Volterra Predator-Prey model}{section.3}% 39
\BOOKMARK [3][-]{subsubsection.3.2.1}{Problem Context}{subsection.3.2}% 40
\BOOKMARK [2][-]{subsection.3.3}{Autoencoding Variational Bayes \(MNIST image generation\)}{section.3}% 41
\BOOKMARK [3][-]{subsubsection.3.3.1}{Problem Context}{subsection.3.3}% 42
\BOOKMARK [2][-]{subsection.3.4}{no idea lol}{section.3}% 43
