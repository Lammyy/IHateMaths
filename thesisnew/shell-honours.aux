\relax 
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{s-intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem Context}{1}}
\citation{DeepLearning}
\citation{neuroplast}
\citation{neuroplast}
\citation{universal}
\citation{neuralstat}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 2}Neural Networks}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Motivation}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Individual Node Structure}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Individual Node Structure}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Activation Function Plots}}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Neural Network Structure}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Neural Network Structure}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Bias-per-node Representation}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Individual Node Structure: Bias-per-node Representation}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Neural Network Structure: Bias-per-node Representation}}{7}}
\citation{DeepLearning}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Choice of Activation Function}{8}}
\citation{xavier}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Weight Initialization}{9}}
\citation{DeepLearning}
\citation{optimneural}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Optimization}{10}}
\citation{optim}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Gradient Descent}}{11}}
\citation{floudas}
\citation{optimneural}
\citation{optimneural}
\citation{adam}
\citation{backprop}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Back-propagation}{13}}
\citation{DeepLearning}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Back-Propagation Algorithm}}{15}}
\citation{blei}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 3}Variational Inference}{16}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Context}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Introduction to Variational Inference}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}The Reverse KL Divergence}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Derivation of the ELBO}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Mean-Field Variational Family}{20}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Coordinate Ascent Variational Inference (CAVI)}}{22}}
\citation{blei}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Example: Bayesian mixture of Gaussians}{23}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces CAVI Algorithm for Bayesian mixture of Gaussians}}{26}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Amortized Inference}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces DAG for Mean-Field Variational Inference}}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces DAG for Amortized Inference}}{27}}
\citation{kingma}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Example: Variational Autoencoder}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}References}{30}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 4}Our Problem}{31}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Objective Derivation}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Implicit Prior}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Implicit Likelihood (\& Prior)}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Class Probability Estimation}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Derivation}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Implicit Prior}{36}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Implicit Prior Class Probability Estimation}}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Implicit Likelihood (\& Prior)}{39}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Implicit Likelihood Class Probability Estimation}}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Optimal functions}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Divergence Minimisation}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Derivation}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Implicit Prior}{46}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Implicit Prior Divergence Minimisation}}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Implicit Likelihood (\& Prior)}{49}}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Implicit Likelihood Divergence Minimisation}}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Optimal functions}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Alternative Derivation of Class Probability Estimation}{53}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 5}Initial Experiment - Inference, "Sprinkler" Example}{55}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Problem Context}{55}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Program Structure}{56}}
\@writefile{loa}{\contentsline {algocf}{\numberline {8}{\ignorespaces Sprinkler Prior-Contrastive Class Probability Estimation}}{58}}
\@writefile{loa}{\contentsline {algocf}{\numberline {9}{\ignorespaces Sprinkler Prior-Contrastive KL Divergence Minimisation}}{59}}
\@writefile{loa}{\contentsline {algocf}{\numberline {10}{\ignorespaces Sprinkler Joint-Contrastive Class Probability Estimation}}{60}}
\@writefile{loa}{\contentsline {algocf}{\numberline {11}{\ignorespaces Sprinkler Joint-Contrastive KL Divergence Minimisation}}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Results}{62}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 6}Theory Crafting}{64}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{64}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Recap because its confusing}{65}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}First and Second Derivatives of all 6 possible algorithms}{66}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Difference between divergences}{68}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Difference between estimators}{68}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 7}Inference Experiments - "Sprinkler"}{72}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Determining optimal activation function}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Experiment Outline}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Results}{72}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Comparing Estimator Accuracies}{73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Experiment Outline}{73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Results}{73}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Comparing Accuracies of Undertrained Estimators}{74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Experiment Outline}{74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Results}{74}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 8}Data Generation - (MNIST image generation)}{75}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Problem Context}{75}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Program Structure}{75}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Results}{76}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 9}Related Work and Discussion}{78}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter 10}Conclusion}{79}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibdata{bible}
\bibcite{blei}{1}
\bibcite{optim}{2}
\bibcite{neuralstat}{3}
\bibcite{backprop}{4}
\bibcite{floudas}{5}
\bibcite{xavier}{6}
\bibcite{DeepLearning}{7}
\bibcite{universal}{8}
\bibcite{kingma}{9}
\bibcite{adam}{10}
\bibcite{optimneural}{11}
\bibcite{neuroplast}{12}
\bibstyle{plain}
\@writefile{toc}{\contentsline {chapter}{\numberline {Appendix A}Kernel Density Estimation}{81}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
