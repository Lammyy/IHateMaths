\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Aims}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Problem Context}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{Results}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{Thesis Structure}{chapter.1}% 5
\BOOKMARK [0][-]{chapter.2}{Background on Neural Networks}{}% 6
\BOOKMARK [1][-]{section.2.1}{Motivation}{chapter.2}% 7
\BOOKMARK [1][-]{section.2.2}{Individual Node Structure}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.3}{Activation Functions}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.4}{Neural Network Structure}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.5}{Weight Initialisation}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.6}{Optimisation}{chapter.2}% 12
\BOOKMARK [1][-]{section.2.7}{Back-Propagation}{chapter.2}% 13
\BOOKMARK [0][-]{chapter.3}{Variational Inference}{}% 14
\BOOKMARK [1][-]{section.3.1}{Context}{chapter.3}% 15
\BOOKMARK [1][-]{section.3.2}{The KL Divergence}{chapter.3}% 16
\BOOKMARK [1][-]{section.3.3}{Introduction to Variational Inference}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.4}{Derivation of the ELBO}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.5}{Mean-Field Variational Family}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.6}{Amortized Inference}{chapter.3}% 20
\BOOKMARK [1][-]{section.3.7}{Example: Variational Autoencoder}{chapter.3}% 21
\BOOKMARK [1][-]{section.3.8}{Problems with Implicit Distributions}{chapter.3}% 22
\BOOKMARK [2][-]{subsection.3.8.1}{Implicit Prior and/or Variational Posterior}{section.3.8}% 23
\BOOKMARK [2][-]{subsection.3.8.2}{Implicit Likelihood}{section.3.8}% 24
\BOOKMARK [0][-]{chapter.4}{Density Ratio Estimation}{}% 25
\BOOKMARK [1][-]{section.4.1}{Class Probability Estimation}{chapter.4}% 26
\BOOKMARK [2][-]{subsection.4.1.1}{Derivation}{section.4.1}% 27
\BOOKMARK [2][-]{subsection.4.1.2}{Prior-Contrastive Algorithm}{section.4.1}% 28
\BOOKMARK [2][-]{subsection.4.1.3}{Joint-Contrastive Algorithm}{section.4.1}% 29
\BOOKMARK [1][-]{section.4.2}{Divergence Minimisation}{chapter.4}% 30
\BOOKMARK [2][-]{subsection.4.2.1}{Derivation}{section.4.2}% 31
\BOOKMARK [2][-]{subsection.4.2.2}{Prior-Contrastive Algorithm}{section.4.2}% 32
\BOOKMARK [2][-]{subsection.4.2.3}{Joint-Contrastive Algorithm}{section.4.2}% 33
\BOOKMARK [2][-]{subsection.4.2.4}{Alternative Derivation of Class Probability Estimation}{section.4.2}% 34
\BOOKMARK [0][-]{chapter.5}{Algorithm Generalisation}{}% 35
\BOOKMARK [1][-]{section.5.1}{Introduction}{chapter.5}% 36
\BOOKMARK [1][-]{section.5.2}{Algorithm Generalisation}{chapter.5}% 37
\BOOKMARK [2][-]{subsection.5.2.1}{Reverse KL Divergence}{section.5.2}% 38
\BOOKMARK [2][-]{subsection.5.2.2}{GAN Divergence}{section.5.2}% 39
\BOOKMARK [1][-]{section.5.3}{Optimization Algorithms}{chapter.5}% 40
\BOOKMARK [2][-]{subsection.5.3.1}{Prior-Contrastive}{section.5.3}% 41
\BOOKMARK [2][-]{subsection.5.3.2}{Joint-Contrastive}{section.5.3}% 42
\BOOKMARK [0][-]{chapter.6}{Comparing Optimal Estimators}{}% 43
\BOOKMARK [1][-]{section.6.1}{Theory}{chapter.6}% 44
\BOOKMARK [1][-]{section.6.2}{Problem Context}{chapter.6}% 45
\BOOKMARK [1][-]{section.6.3}{Program Structure}{chapter.6}% 46
\BOOKMARK [1][-]{section.6.4}{Results}{chapter.6}% 47
\BOOKMARK [0][-]{chapter.7}{Comparing Undertrained Estimators}{}% 48
\BOOKMARK [1][-]{section.7.1}{Theory}{chapter.7}% 49
\BOOKMARK [2][-]{subsection.7.1.1}{Estimator Bounds}{section.7.1}% 50
\BOOKMARK [2][-]{subsection.7.1.2}{First and Second Derivatives of Estimator Loss Functions}{section.7.1}% 51
\BOOKMARK [2][-]{subsection.7.1.3}{Displacement of Estimator Optimal Values}{section.7.1}% 52
\BOOKMARK [1][-]{section.7.2}{Experiment Outline}{chapter.7}% 53
\BOOKMARK [1][-]{section.7.3}{Results}{chapter.7}% 54
\BOOKMARK [0][-]{chapter.8}{Data Generation - \(MNIST image generation\)}{}% 55
\BOOKMARK [1][-]{section.8.1}{Experiment Outline}{chapter.8}% 56
\BOOKMARK [1][-]{section.8.2}{Low Dimensional Experiment Results}{chapter.8}% 57
\BOOKMARK [1][-]{section.8.3}{High Dimensional Experiment Results}{chapter.8}% 58
\BOOKMARK [0][-]{chapter.9}{Conclusion and Further Research}{}% 59
\BOOKMARK [1][-]{section.9.1}{Further Research}{chapter.9}% 60
\BOOKMARK [0][-]{section.9.1}{References}{}% 61
\BOOKMARK [0][-]{appendix.A}{Proofs}{}% 62
\BOOKMARK [1][-]{appendix.A.1}{Proof of Proposition 2.6.2}{appendix.A}% 63
\BOOKMARK [1][-]{appendix.A.2}{Proof of Lemma 3.7.1}{appendix.A}% 64
\BOOKMARK [1][-]{appendix.A.3}{Proof of Lemma 4.1.1}{appendix.A}% 65
\BOOKMARK [1][-]{appendix.A.4}{Proof of Lemma 4.2.2}{appendix.A}% 66
\BOOKMARK [0][-]{appendix.B}{Algorithms}{}% 67
\BOOKMARK [1][-]{appendix.B.1}{Back-Propagation Algorithm}{appendix.B}% 68
\BOOKMARK [1][-]{appendix.B.2}{Coordinate Ascent Variational Inference Algorithm}{appendix.B}% 69
\BOOKMARK [1][-]{appendix.B.3}{Algorithms for ``Sprinkler" Experiment}{appendix.B}% 70
\BOOKMARK [0][-]{appendix.C}{Mean Field Variational Inference Example}{}% 71
\BOOKMARK [0][-]{appendix.D}{Kernel Density Estimation}{}% 72
\BOOKMARK [0][-]{appendix.E}{Prior-Contrastive Optimal Estimator Experiment Plots}{}% 73
\BOOKMARK [0][-]{appendix.F}{Second Functional Derivatives of Direct Log Ratio Estimator Losses}{}% 74
