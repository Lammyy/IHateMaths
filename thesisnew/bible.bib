@book{DeepLearning,
    title="Deep Learning",
    author="Ian Goodfellow and Yoshua Bengio and Aaron Courville",
    publisher={MIT Press},
    url="{http://www.deeplearningbook.org}",
    year={2016}
}

@article{neuroplast,
title = "Neuronal plasticity as an adaptive property of the central nervous system",
journal = "Annals of Anatomy - Anatomischer Anzeiger",
volume = "174",
number = "5",
pages = "383 - 391",
year = "1992",
issn = "0940-9602",
doi = "https://doi.org/10.1016/S0940-9602(11)80255-4",
url = "http://www.sciencedirect.com/science/article/pii/S0940960211802554",
author = "Karl Zilles",
keywords = "Plasticity, Brain, Cytoarchitecture, Callosal system, Receptor, Visual cortex, Hippocampus"
}

@article{universal,
title = "Approximation capabilities of multilayer feedforward networks",
journal = "Neural Networks",
volume = "4",
number = "2",
pages = "251 - 257",
year = "1991",
issn = "0893-6080",
doi = "https://doi.org/10.1016/0893-6080(91)90009-T",
url = "http://www.sciencedirect.com/science/article/pii/089360809190009T",
author = "Kurt Hornik",
keywords = "Multilayer feedforward networks, Activation function, Universal approximation capabilities, Input environment measure, () approximation, Uniform approximation, Sobolev spaces, Smooth approximation"
}

@article{neuralstat,
author = "Cheng, Bing and Titterington, D. M.",
doi = "10.1214/ss/1177010638",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "02",
number = "1",
pages = "2--30",
publisher = "The Institute of Mathematical Statistics",
title = "Neural Networks: A Review from a Statistical Perspective",
url = "https://doi.org/10.1214/ss/1177010638",
volume = "9",
year = "1994"
}

@inproceedings{xavier,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@article{optimneural,
  author    = {Sebastian Ruder},
  title     = {An overview of gradient descent optimization algorithms},
  journal   = {CoRR},
  volume    = {abs/1609.04747},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.04747},
  archivePrefix = {arXiv},
  eprint    = {1609.04747},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Ruder16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{optim, place={Cambridge}, title={Convex Optimization}, DOI={10.1017/CBO9780511804441}, publisher={Cambridge University Press}, author={Boyd, Stephen and Vandenberghe, Lieven}, year={2004}}

@book{floudas,
 author = {Floudas, Christodoulos A.},
 title = {Deterministic Global Optimization: Theory, Methods and (NONCONVEX OPTIMIZATION AND ITS APPLICATIONS Volume 37) (Nonconvex Optimization and Its Applications)},
 year = {2005},
 isbn = {0792360141},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@article{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {CoRR},
  volume    = {abs/1412.6980},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.6980},
  archivePrefix = {arXiv},
  eprint    = {1412.6980},
  timestamp = {Mon, 13 Aug 2018 16:47:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{backprop,
author = {E. Rumelhart, David and E. Hinton, Geoffrey and J. Williams, Ronald},
year = {1986},
month = {10},
pages = {533-536},
title = {Learning Representations by Back Propagating Errors},
volume = {323},
booktitle = {Nature}
}

@article{blei,
author = {David M. Blei and Alp Kucukelbir and Jon D. McAuliffe},
title = {Variational Inference: A Review for Statisticians},
journal = {Journal of the American Statistical Association},
volume = {112},
number = {518},
pages = {859-877},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2017.1285773},

URL = { 
        https://doi.org/10.1080/01621459.2017.1285773
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2017.1285773
    
}

}
@ARTICLE{kingma,
   author = {{Kingma}, D.~P and {Welling}, M.},
    title = "{Auto-Encoding Variational Bayes}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1312.6114},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2013,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6114K},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{ADVVI,
  title={Advances in Variational Inference},
  author={Cheng Zhang and Judith B{\"u}tepage and Hedvig Kjellstr{\"o}m and Stephan Mandt},
  journal={CoRR},
  year={2017},
  volume={abs/1711.05597}
}
@ARTICLE{ali,
   author = {{Dumoulin}, V. and {Belghazi}, I. and {Poole}, B. and {Mastropietro}, O. and 
	{Lamb}, A. and {Arjovsky}, M. and {Courville}, A.},
    title = "{Adversarially Learned Inference}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1606.00704},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2016,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160600704D},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{tran,
   author = {{Tran}, D. and {Ranganath}, R. and {Blei}, D.~M.},
    title = "{Hierarchical Implicit Models and Likelihood-Free Variational Inference}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1702.08896},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Statistics - Methodology},
     year = 2017,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170208896T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{huszar,
   author = {{Husz{\'a}r}, F.},
    title = "{Variational Inference using Implicit Distributions}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1702.08235},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2017,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170208235H},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{mnist,
author = {Simard, Patrice Y. and Steinkraus, Dave and Platt, John},
title = {Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis},
booktitle = {},
year = {2003},
month = {August},
abstract = {

Neural networks are a powerful technology for classification of visual inputs arising from documents. However, there is a confusing plethora of different neural network methods that are used in the literature and in industry. This paper describes a set of concrete best practices that document analysis researchers can use to get good results with neural networks. The most important practice is getting a training set as large as possible: we expand the training set by adding a new form of distorted data. The next most important practice is that convolutional neural networks are better suited for visual document tasks than fully connected networks. We propose that a simple “do-it-yourself” implementation of convolution with a flexible architecture is suitable for many visual document problems. This simple convolutional neural network does not require complex methods, such as momentum, weight decay, structure dependent learning rates, averaging layers, tangent prop, or even finely-tuning the architecture. The end result is a very simple yet general architecture which can yield state-of-the-art performance for document analysis. We illustrate our claims on the MNIST set of English digit images.


},
publisher = {Institute of Electrical and Electronics Engineers, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis/},
address = {},
pages = {},
journal = {},
volume = {},
chapter = {},
isbn = {},
}

@Article{cybenko,
author="Cybenko, G.",
title="Approximation by superpositions of a sigmoidal function",
journal="Mathematics of Control, Signals and Systems",
year="1989",
month="Dec",
day="01",
volume="2",
number="4",
pages="303--314",
abstract="In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.",
issn="1435-568X",
doi="10.1007/BF02551274",
url="https://doi.org/10.1007/BF02551274"
}
@book{gelman,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Rubin, Donald B.},
  biburl = {https://www.bibsonomy.org/bibtex/2f7d7012c81d89965db2cfedf698f53c7/jwbowers},
  citeulike-article-id = {106919},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  edition = {2nd ed.},
  interhash = {9c5f4ce8c45003080aa52ac74eb4c78c},
  intrahash = {f7d7012c81d89965db2cfedf698f53c7},
  keywords = {bayesian statistics},
  publisher = {Chapman and Hall/CRC},
  timestamp = {2009-10-28T04:43:08.000+0100},
  title = {Bayesian Data Analysis},
  year = 2004
}

@article {KL,
	author = {Heilprin, L. B.},
	title = {Information Theory and Statistics. Solomon Kullback. Wiley, New York; Chapman and Hall, London, 1959. xvii + 395 pp. Illus. $12.50},
	volume = {131},
	number = {3404},
	pages = {917--918},
	year = {1960},
	doi = {10.1126/science.131.3404.917-b},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/131/3404/917.3},
	eprint = {http://science.sciencemag.org/content/131/3404/917.3.full.pdf},
	journal = {Science}
}

@inproceedings{giordano,
 author = {Giordano, Ryan and Broderick, Tamara and Jordan, Michael},
 title = {Linear Response Methods for Accurate Covariance Estimates from Mean Field Variational Bayes},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1},
 series = {NIPS'15},
 year = {2015},
 location = {Montreal, Canada},
 pages = {1441--1449},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2969239.2969400},
 acmid = {2969400},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA}
} 

@ARTICLE{mescheder,
  author    = {Lars M. Mescheder and
               Sebastian Nowozin and
               Andreas Geiger},
  title     = "{Adversarial Variational Bayes: Unifying Variational Autoencoders and
               Generative Adversarial Networks}",
  journal   = {CoRR},
  volume    = {abs/1701.04722},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.04722},
  archivePrefix = {arXiv},
  eprint    = {1701.04722},
  timestamp = {Mon, 13 Aug 2018 16:48:26 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MeschederNG17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{tiao,
   author = {Tiao, L.~C. and Bonilla, E.~V. and Ramos, F.},
    title = "{Cycle-Consistent Adversarial Learning as Approximate Bayesian Inference}",
  journal = {ArXiv e-prints},
archivePrefix = {arXiv},
   eprint = {1806.01771},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = {2018},
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180601771T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}