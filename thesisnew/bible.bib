@book{DeepLearning,
    title="Deep Learning",
    author="Ian Goodfellow and Yoshua Bengio and Aaron Courville",
    publisher={MIT Press},
    url="{http://www.deeplearningbook.org}",
    year={2016}
}
@article{neuroplast,
title = "Neuronal plasticity as an adaptive property of the central nervous system",
journal = "Annals of Anatomy - Anatomischer Anzeiger",
volume = "174",
number = "5",
pages = "383 - 391",
year = "1992",
issn = "0940-9602",
doi = "https://doi.org/10.1016/S0940-9602(11)80255-4",
url = "http://www.sciencedirect.com/science/article/pii/S0940960211802554",
author = "Karl Zilles",
keywords = "Plasticity, Brain, Cytoarchitecture, Callosal system, Receptor, Visual cortex, Hippocampus"
}

@book{haykin,
 author = {Haykin, Simon},
 title = {Neural Networks: A Comprehensive Foundation},
 year = {1998},
 isbn = {0132733501},
 edition = {2nd},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA}
} 
@ARTICLE{bgan,
   author = {{Uehara}, M. and {Sato}, I. and {Suzuki}, M. and {Nakayama}, K. and 
	{Matsuo}, Y.},
    title = "{Generative Adversarial Nets from a Density Ratio Estimation Perspective}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1610.02920},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning},
     year = 2016,
    month = oct,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv161002920U},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@inproceedings{leaky,
  title={Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  author={Andrew L. Maas},
  year={2013}
}

@article{universal,
title = "Approximation capabilities of multilayer feedforward networks",
journal = "Neural Networks",
volume = "4",
number = "2",
pages = "251 - 257",
year = "1991",
issn = "0893-6080",
doi = "https://doi.org/10.1016/0893-6080(91)90009-T",
url = "http://www.sciencedirect.com/science/article/pii/089360809190009T",
author = "Kurt Hornik",
keywords = "Multilayer feedforward networks, Activation function, Universal approximation capabilities, Input environment measure, () approximation, Uniform approximation, Sobolev spaces, Smooth approximation"
}

@article{neuralstat,
author = "Cheng, Bing and Titterington, D. M.",
doi = "10.1214/ss/1177010638",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "02",
number = "1",
pages = "2--30",
publisher = "The Institute of Mathematical Statistics",
title = "Neural Networks: A Review from a Statistical Perspective",
url = "https://doi.org/10.1214/ss/1177010638",
volume = "9",
year = "1994"
}

@inproceedings{xavier,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@article{optimneural,
  author    = {Sebastian Ruder},
  title     = {An overview of gradient descent optimization algorithms},
  journal   = {CoRR},
  volume    = {abs/1609.04747},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.04747},
  archivePrefix = {arXiv},
  eprint    = {1609.04747},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Ruder16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{optim, place={Cambridge}, title={Convex Optimization}, DOI={10.1017/CBO9780511804441}, publisher={Cambridge University Press}, author={Boyd, Stephen and Vandenberghe, Lieven}, year={2004}}

@book{floudas,
 author = {Floudas, Christodoulos A.},
 title = {Deterministic Global Optimization: Theory, Methods and (NONCONVEX OPTIMIZATION AND ITS APPLICATIONS Volume 37) (Nonconvex Optimization and Its Applications)},
 year = {2005},
 isbn = {0792360141},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg}
} 

@article{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {CoRR},
  volume    = {abs/1412.6980},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.6980},
  archivePrefix = {arXiv},
  eprint    = {1412.6980},
  timestamp = {Mon, 13 Aug 2018 16:47:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaB14}
}

@article{backprop,
author = {E. Rumelhart, David and E. Hinton, Geoffrey and J. Williams, Ronald},
year = {1986},
month = {10},
pages = {533-536},
title = {Learning Representations by Back Propagating Errors},
volume = {323},
booktitle = {Nature}
}

@article{blei,
author = {David M. Blei and Alp Kucukelbir and Jon D. McAuliffe},
title = {Variational Inference: A Review for Statisticians},
journal = {Journal of the American Statistical Association},
volume = {112},
number = {518},
pages = {859-877},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2017.1285773},

URL = { 
        https://doi.org/10.1080/01621459.2017.1285773
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2017.1285773
    
}

}

@article{relu1,
  title={Direct Density Ratio Estimation with Convolutional Neural Networks with Application in Outlier Detection},
  author={Hyunha Nam and Masashi Sugiyama},
  journal={IEICE Transactions on Information and Systems},
  volume={E98.D},
  number={5},
  pages={1073-1079},
  year={2015},
  doi={10.1587/transinf.2014EDP7335}
}
@article{relu2,
  title={DecideNet: Counting Varying Density Crowds Through Attention Guided Detection and Density Estimation},
  author={Jiang Liu and Chenqiang Gao and Deyu Meng and Alexander G. Hauptmann},
  journal={CoRR},
  year={2017},
  volume={abs/1712.06679}
}
@ARTICLE{vae,
   author = {{Doersch}, C.},
    title = "{Tutorial on Variational Autoencoders}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1606.05908},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2016,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160605908D},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{kingma,
   author = {{Kingma}, D.~P and {Welling}, M.},
    title = "{Auto-Encoding Variational Bayes}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1312.6114},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2013,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6114K},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{ADVVI,
  title={Advances in Variational Inference},
  author={Cheng Zhang and Judith B{\"u}tepage and Hedvig Kjellstr{\"o}m and Stephan Mandt},
  journal={CoRR},
  year={2017},
  volume={abs/1711.05597}
}

@article{wang,
 author = {Wang, Qing and Kulkarni, Sanjeev R. and Verd\'{u}, Sergio},
 title = {Divergence Estimation for Multidimensional Densities via K-nearest-neighbor Distances},
 journal = {IEEE Trans. Inf. Theor.},
 issue_date = {May 2009},
 volume = {55},
 number = {5},
 month = may,
 year = {2009},
 issn = {0018-9448},
 pages = {2392--2405},
 numpages = {14},
 url = {http://dx.doi.org/10.1109/TIT.2009.2016060},
 doi = {10.1109/TIT.2009.2016060},
 acmid = {1669521},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Divergence, Kullback\&\#x2013;Leibler, Kullback-Leibler, divergence, information measure, nearest-neighbor, partition, random vector, universal estimation},
} 

@inproceedings{vincent,
 author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
 title = {Extracting and Composing Robust Features with Denoising Autoencoders},
 booktitle = {Proceedings of the 25th International Conference on Machine Learning},
 series = {ICML '08},
 year = {2008},
 isbn = {978-1-60558-205-4},
 location = {Helsinki, Finland},
 pages = {1096--1103},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1390156.1390294},
 doi = {10.1145/1390156.1390294},
 acmid = {1390294},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


@article{ali,
   author = {{Dumoulin}, V. and {Belghazi}, I. and {Poole}, B. and {Mastropietro}, O. and 
	{Lamb}, A. and {Arjovsky}, M. and {Courville}, A.},
    title = "{Adversarially Learned Inference}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1606.00704},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2016,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160600704D},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{tran,
   author = {{Tran}, D. and {Ranganath}, R. and {Blei}, D.~M.},
    title = "{Hierarchical Implicit Models and Likelihood-Free Variational Inference}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1702.08896},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Statistics - Methodology},
     year = 2017,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170208896T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{huszar,
   author = {{Husz{\'a}r}, F.},
    title = "{Variational Inference using Implicit Distributions}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1702.08235},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = 2017,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170208235H},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{mnist,
  title={Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis},
  author={Patrice Y. Simard and David Steinkraus and John C. Platt},
  booktitle={ICDAR},
  year={2003}
}

@INBOOK{kolen, 
author={John F. Kolen and Stefan C. Kremer}, 
booktitle={A Field Guide to Dynamical Recurrent Networks}, 
title={Gradient Flow in Recurrent Nets: The Difficulty of Learning LongTerm Dependencies}, 
year={2001}, 
volume={}, 
number={}, 
pages={}, 
keywords={}, 
doi={10.1109/9780470544037.ch14}, 
ISSN={}, 
publisher={IEEE}, 
isbn={}, 
url={https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5264952}}

@InProceedings{sparse,
  title = 	 {Deep Sparse Rectifier Neural Networks},
  author = 	 {Xavier Glorot and Antoine Bordes and Yoshua Bengio},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {315--323},
  year = 	 {2011},
  editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dud√≠k},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
  url = 	 {http://proceedings.mlr.press/v15/glorot11a.html},
  abstract = 	 {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training. [pdf]}
}

@book{snyman,
author = {Snyman, J},
year = {2005},
month = {02},
pages = {},
title = {Practical Mathematical Optimization},
isbn = {0-387-24348-8, 257 pages}
}

@article{wu,
author = {Wu, Huaiqin},
year = {2009},
month = {09},
pages = {3432-3441},
title = {Global stability analysis of a general class of discontinuous neural networks with linear growth activation functions},
volume = {179},
booktitle = {Inf. Sci.}
}
@article{cybenko,
author="Cybenko, G.",
title="Approximation by superpositions of a sigmoidal function",
journal="Mathematics of Control, Signals and Systems",
year="1989",
month="Dec",
day="01",
volume="2",
number="4",
pages="303--314",
abstract="In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.",
issn="1435-568X",
doi="10.1007/BF02551274",
url="https://doi.org/10.1007/BF02551274"
}

@book{gelman,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Rubin, Donald B.},
  biburl = {https://www.bibsonomy.org/bibtex/2f7d7012c81d89965db2cfedf698f53c7/jwbowers},
  citeulike-article-id = {106919},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  edition = {2nd ed.},
  interhash = {9c5f4ce8c45003080aa52ac74eb4c78c},
  intrahash = {f7d7012c81d89965db2cfedf698f53c7},
  keywords = {bayesian statistics},
  publisher = {Chapman and Hall/CRC},
  timestamp = {2009-10-28T04:43:08.000+0100},
  title = {Bayesian Data Analysis},
  year = {2004}
}

@inproceedings{giordano,
 author = {Giordano, Ryan and Broderick, Tamara and Jordan, Michael},
 title = {Linear Response Methods for Accurate Covariance Estimates from Mean Field Variational Bayes},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1},
 series = {NIPS'15},
 year = {2015},
 location = {Montreal, Canada},
 pages = {1441--1449},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2969239.2969400},
 acmid = {2969400},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA}
} 

@Inbook{lecun,
author="LeCun, Yann A.
and Bottou, L{\'e}on
and Orr, Genevieve B.
and M{\"u}ller, Klaus-Robert",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Efficient BackProp",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="9--48",
abstract="The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_3",
url="https://doi.org/10.1007/978-3-642-35289-8_3"
}



@article{nowozin,
author = {Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
year = {2016},
month = {06},
pages = {},
title = {f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization}
}
@article{mescheder,
  author    = {Lars M. Mescheder and
               Sebastian Nowozin and
               Andreas Geiger},
  title     = "{Adversarial Variational Bayes: Unifying Variational Autoencoders and
               Generative Adversarial Networks}",
  journal   = {CoRR},
  volume    = {abs/1701.04722},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.04722},
  archivePrefix = {arXiv},
  eprint    = {1701.04722},
  timestamp = {Mon, 13 Aug 2018 16:48:26 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MeschederNG17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{tiao,
   author = {Tiao, L.~C. and Bonilla, E.~V. and Ramos, F.},
    title = "{Cycle-Consistent Adversarial Learning as Approximate Bayesian Inference}",
  journal = {ArXiv e-prints},
archivePrefix = {arXiv},
   eprint = {1806.01771},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
     year = {2018},
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180601771T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{mohamed,
   author = {{Mohamed}, S. and {Lakshminarayanan}, B.},
    title = "{Learning in Implicit Generative Models}",
  journal = {ArXiv e-prints},
archivePrefix = {arXiv},
   eprint = {1610.03483},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation},
     year = {2016},
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv161003483M},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@book{sugiyama, 
place={Cambridge}, 
title="{Density Ratio Estimation in Machine Learning}", 
DOI={10.1017/CBO9781139035613}, 
publisher={Cambridge University Press}, 
author={Sugiyama, Masashi and Suzuki, Taiji and Kanamori, Takafumi}, 
year={2012}
}
@INPROCEEDINGS{JS, 
author={B. Fuglede and F. Topsoe}, 
booktitle={International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings.}, 
title={Jensen-Shannon divergence and Hilbert space embedding}, 
year={2004}, 
volume={}, 
number={}, 
pages={31-}, 
keywords={Hilbert spaces;information theory;redundancy;probability;Jensen-Shannon divergence;Hilbert space embedding;redundancy;Hilbert space;Kernel;Mathematics;Probability distribution;Entropy;Convergence;Councils;Spirals;Concrete}, 
doi={10.1109/ISIT.2004.1365067}, 
ISSN={}, 
month={June},}
@article{gan,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Y},
year = {2014},
month = {06},
pages = {},
title = "{Generative Adversarial Networks}",
volume = {3},
booktitle = {Advances in Neural Information Processing Systems}
}

@article{ais,
  title={On the Quantitative Analysis of Decoder-Based Generative Models},
  author={Yuhuai Wu and Yuri Burda and Ruslan Salakhutdinov and Roger B. Grosse},
  journal={CoRR},
  year={2016},
  volume={abs/1611.04273}
}

@book{beck,
 author = {Beck, Amir},
 title = {Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MATLAB},
 year = {2014},
 isbn = {1611973643, 9781611973648},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
} 

@article{nguyen,
 author = {Nguyen, XuanLong and Wainwright, Martin J. and Jordan, Michael I.},
 title = "{Estimating Divergence Functionals and the Likelihood Ratio by Convex Risk Minimization}",
 journal = {IEEE Trans. Inf. Theor.},
 issue_date = {November 2010},
 volume = {56},
 number = {11},
 year = {2010},
 issn = {0018-9448},
 pages = {5847--5861},
 numpages = {15},
 url = {http://dx.doi.org/10.1109/TIT.2010.2068870},
 doi = {10.1109/TIT.2010.2068870},
 acmid = {1921980},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA}
} 

@Inbook{bengio,
author="Bengio, Yoshua",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Practical Recommendations for Gradient-Based Training of Deep Architectures",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="437--478",
abstract="Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most commonly used hyperparameters, in particular in the context of learning algorithms based on back-propagated gradient and gradient-based optimization. It also discusses how to deal with the fact that more interesting results can be obtained when allowing one to adjust many hyper-parameters. Overall, it describes elements of the practice used to successfully and efficiently train and debug large-scale and often deep multi-layer neural networks. It closes with open questions about the training difficulties observed with deeper architectures.",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_26",
url="https://doi.org/10.1007/978-3-642-35289-8_26"
}



@inproceedings{batch,
 author = {Li, Mu and Zhang, Tong and Chen, Yuqiang and Smola, Alexander J.},
 title = {Efficient Mini-batch Training for Stochastic Optimization},
 booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '14},
 year = {2014},
 isbn = {978-1-4503-2956-9},
 location = {New York, New York, USA},
 pages = {661--670},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2623330.2623612},
 doi = {10.1145/2623330.2623612},
 acmid = {2623612},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {big data, distributed computing, machine learning, minibatch, stochastic gradient descent},
} 

@article{goodman,
author = { Leo A.   Goodman },
title = {On the Exact Variance of Products},
journal = {Journal of the American Statistical Association},
volume = {55},
number = {292},
pages = {708-713},
year  = {1960},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1960.10483369},

URL = { 
        https://www.tandfonline.com/doi/abs/10.1080/01621459.1960.10483369
    
},
eprint = { 
        https://www.tandfonline.com/doi/pdf/10.1080/01621459.1960.10483369
    
}

}

@book{bishop,
 author = {Bishop, Christopher M.},
 title = {Neural Networks for Pattern Recognition},
 year = {1995},
 isbn = {0198538642},
 publisher = {Oxford University Press, Inc.},
 address = {New York, NY, USA}
}

@book{pattern,
 author = {Bishop, Christopher M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 
@article{explain,
author = {P. Wellman, Michael and Henrion, Max},
year = {1993},
month = {04},
pages = {287-292},
title = {Explaining `explaining away'},
volume = {15},
booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on}
}

@book{KL,
  added-at = {2008-09-16T23:39:07.000+0200},
  address = {New York},
  author = {Kullback, Solomon},
  biburl = {https://www.bibsonomy.org/bibtex/28d0af9cdd06af73190b01cc1e04da70b/brian.mingus},
  booktitle = {Information Theory and Statistics},
  description = {CCNLab BibTeX},
  interhash = {03b56ca50da39d05c8832fb6f814ddda},
  intrahash = {8d0af9cdd06af73190b01cc1e04da70b},
  keywords = {stats},
  publisher = {Wiley},
  timestamp = {2008-09-16T23:40:28.000+0200},
  title = {Information Theory and Statistics},
  year = 1959
}

